{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hawaiian-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "certified-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSA_Pokemon_df = pd.read_csv('PWCC_Pokemon.csv')\n",
    "PSA_Pokemon_df_8 = PSA_Pokemon_df[(PSA_Pokemon_df.Rating == 8)]\n",
    "PSA_Pokemon_df_10 = PSA_Pokemon_df[(PSA_Pokemon_df.Rating == 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "standard-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_8 = [[y.split('[')[1].split(']')[0].split(', ')[x][1:-1] for x in range(len(y.split('[')[1].split(']')[0].split(', ')))] for y in list(PSA_Pokemon_df_8.uuid)]\n",
    "uuid_10 = [[y.split('[')[1].split(']')[0].split(', ')[x][1:-1] for x in range(len(y.split('[')[1].split(']')[0].split(', ')))] for y in list(PSA_Pokemon_df_10.uuid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "similar-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_eights = [f.split('.jpg')[0] for f in listdir('PWCC/8') if isfile(join('PWCC/8', f))]\n",
    "available_tens = [f.split('.jpg')[0] for f in listdir('PWCC/10') if isfile(join('PWCC/10', f))]\n",
    "\n",
    "eights_front = []\n",
    "eights_back = []\n",
    "for i in uuid_8:\n",
    "    if (i[0] in available_eights) and (i[0] in available_eights):\n",
    "        eights_front.append('PWCC/8/'+str(i[0])+'.jpg')\n",
    "        eights_back.append('PWCC/8/'+str(i[1])+'.jpg')\n",
    "        \n",
    "tens_front = []\n",
    "tens_back = []\n",
    "for i in uuid_10:\n",
    "    if (i[0] in available_tens) and (i[0] in available_tens):\n",
    "        tens_front.append('PWCC/10/'+str(i[0])+'.jpg')\n",
    "        tens_back.append('PWCC/10/'+str(i[1])+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bearing-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3000\n",
       "1    3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 3000\n",
    "\n",
    "image_front = eights_front[:sample_size] + tens_front[:sample_size]\n",
    "image_back = eights_back[:sample_size] + tens_back[:sample_size]\n",
    "\n",
    "y = [1 for i in tens_front[:sample_size]] + [0 for i in eights_front[:sample_size]]\n",
    "y = pd.DataFrame(y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indirect-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8e72fd7b98420484ea1abfdfc26bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d3179b9ada41edb20e1c13dd598ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "res = 224\n",
    "\n",
    "def load_image(file):\n",
    "    try:\n",
    "        image = Image.open(\n",
    "            file\n",
    "        ).convert('LA').resize((res, res))\n",
    "        arr = np.array(image)\n",
    "    except:\n",
    "        print('didnt work')\n",
    "        arr = np.zeros((res, res, 2))\n",
    "    return arr\n",
    "\n",
    "x_front = np.array([load_image(i) for i in tqdm(image_front)])\n",
    "x_back = np.array([load_image(i) for i in tqdm(image_back)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compliant-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_front_tr, x_front_vl, x_back_tr, x_back_vl, y_tr, y_vl = train_test_split(\n",
    "    x_front,\n",
    "    x_back,\n",
    "    y,\n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comic-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, GRU, LSTM, Bidirectional, TimeDistributed, Attention, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "in_front = keras.Input(batch_shape=(None, (res), (res), 2))\n",
    "in_back = keras.Input(batch_shape=(None, (res), (res), 2))\n",
    "\n",
    "#Front\n",
    "cov_0 = Conv2D(32, (5, 5), activation='relu')(in_front)\n",
    "pool_0 = MaxPool2D((2, 2))(cov_0)\n",
    "cov_1 = Conv2D(64, (5, 5), activation='relu')(pool_0)\n",
    "pool_1 = MaxPool2D((2, 2))(cov_1)\n",
    "cov_2 = Conv2D(64, (5, 5), activation='relu')(pool_1)\n",
    "pool_2 = MaxPool2D((2, 2))(cov_2)\n",
    "cov_3 = Conv2D(64, (5, 5), activation='relu')(pool_2)\n",
    "pool_3 = MaxPool2D((6, 6))(cov_3)\n",
    "flatten = Flatten()(pool_3)\n",
    "\n",
    "#Back\n",
    "cov_0_1 = Conv2D(32, (5, 5), activation='relu')(in_back)\n",
    "pool_0_1 = MaxPool2D((2, 2))(cov_0_1)\n",
    "cov_1_1 = Conv2D(64, (5, 5), activation='relu')(pool_0_1)\n",
    "pool_1_1 = MaxPool2D((2, 2))(cov_1_1)\n",
    "cov_2_1 = Conv2D(64, (5, 5), activation='relu')(pool_1_1)\n",
    "pool_2_1 = MaxPool2D((2, 2))(cov_2_1)\n",
    "cov_3_1 = Conv2D(64, (5, 5), activation='relu')(pool_2_1)\n",
    "pool_3_1 = MaxPool2D((6, 6))(cov_3_1)\n",
    "flatten_1 = Flatten()(pool_3_1)\n",
    "\n",
    "\n",
    "fused = tf.concat([flatten, flatten_1], axis=-1)\n",
    "\n",
    "fc = Dense(64, activation='relu')(fused)\n",
    "pred = Dense(1, activation='sigmoid')(fc)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs={\n",
    "        'in_front': in_front,\n",
    "        'in_back': in_back\n",
    "    },\n",
    "    outputs=pred,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scenic-prairie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 2) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 224, 224, 2) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 220, 220, 32) 1632        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 220, 220, 32) 1632        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 110, 110, 32) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 110, 110, 32) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 106, 106, 64) 51264       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 106, 106, 64) 51264       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 53, 53, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 53, 53, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 49, 49, 64)   102464      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 49, 49, 64)   102464      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 24, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 24, 24, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 20, 20, 64)   102464      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 20, 20, 64)   102464      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 64)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 64)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 576)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 576)          0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 1152)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           73792       tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            65          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 589,505\n",
      "Trainable params: 589,505\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(lr=0.0003),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'AUC']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "driving-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 324s 2s/step - loss: 2.9561 - accuracy: 0.5775 - auc: 0.5925 - val_loss: 0.6314 - val_accuracy: 0.6258 - val_auc: 0.7988\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 322s 2s/step - loss: 0.5656 - accuracy: 0.7080 - auc: 0.7815 - val_loss: 0.5175 - val_accuracy: 0.7367 - val_auc: 0.8238\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 326s 2s/step - loss: 0.5258 - accuracy: 0.7303 - auc: 0.8132 - val_loss: 0.5285 - val_accuracy: 0.7233 - val_auc: 0.8264\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 322s 2s/step - loss: 0.4729 - accuracy: 0.7693 - auc: 0.8582 - val_loss: 0.6359 - val_accuracy: 0.6867 - val_auc: 0.8367\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 328s 2s/step - loss: 0.4602 - accuracy: 0.7765 - auc: 0.8631 - val_loss: 0.5246 - val_accuracy: 0.7342 - val_auc: 0.8511\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 324s 2s/step - loss: 0.4199 - accuracy: 0.8046 - auc: 0.8887 - val_loss: 0.4762 - val_accuracy: 0.7792 - val_auc: 0.8565\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 319s 2s/step - loss: 0.4027 - accuracy: 0.8085 - auc: 0.8981 - val_loss: 0.4915 - val_accuracy: 0.7683 - val_auc: 0.8541\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 327s 2s/step - loss: 0.3571 - accuracy: 0.8416 - auc: 0.9224 - val_loss: 0.4974 - val_accuracy: 0.7675 - val_auc: 0.8656\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 325s 2s/step - loss: 0.3555 - accuracy: 0.8459 - auc: 0.9234 - val_loss: 0.4720 - val_accuracy: 0.7858 - val_auc: 0.8643\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 323s 2s/step - loss: 0.3263 - accuracy: 0.8556 - auc: 0.9358 - val_loss: 0.6266 - val_accuracy: 0.7183 - val_auc: 0.8777\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 319s 2s/step - loss: 0.3290 - accuracy: 0.8598 - auc: 0.9357 - val_loss: 0.4420 - val_accuracy: 0.8083 - val_auc: 0.8834\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 323s 2s/step - loss: 0.2733 - accuracy: 0.8973 - auc: 0.9548 - val_loss: 0.4691 - val_accuracy: 0.7858 - val_auc: 0.8831\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 324s 2s/step - loss: 0.2565 - accuracy: 0.8896 - auc: 0.9612 - val_loss: 0.5542 - val_accuracy: 0.7717 - val_auc: 0.8848\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 324s 2s/step - loss: 0.2541 - accuracy: 0.9002 - auc: 0.9613 - val_loss: 0.4938 - val_accuracy: 0.7967 - val_auc: 0.8866\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 323s 2s/step - loss: 0.2331 - accuracy: 0.9075 - auc: 0.9673 - val_loss: 0.4834 - val_accuracy: 0.7975 - val_auc: 0.8785\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 316s 2s/step - loss: 0.1941 - accuracy: 0.9253 - auc: 0.9781 - val_loss: 0.5087 - val_accuracy: 0.8025 - val_auc: 0.8894\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 320s 2s/step - loss: 0.1751 - accuracy: 0.9312 - auc: 0.9825 - val_loss: 0.4965 - val_accuracy: 0.8058 - val_auc: 0.8832\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 323s 2s/step - loss: 0.1666 - accuracy: 0.9360 - auc: 0.9836 - val_loss: 0.5677 - val_accuracy: 0.7750 - val_auc: 0.8828\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 317s 2s/step - loss: 0.1513 - accuracy: 0.9468 - auc: 0.9867 - val_loss: 0.5803 - val_accuracy: 0.7767 - val_auc: 0.8814\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 315s 2s/step - loss: 0.1274 - accuracy: 0.9549 - auc: 0.9907 - val_loss: 0.6836 - val_accuracy: 0.7700 - val_auc: 0.8776\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 328s 2s/step - loss: 0.0996 - accuracy: 0.9669 - auc: 0.9949 - val_loss: 0.5875 - val_accuracy: 0.8025 - val_auc: 0.8829\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x={\n",
    "        'in_front': x_front_tr,\n",
    "        'in_back': x_back_tr\n",
    "    },\n",
    "    y=y_tr,\n",
    "    \n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "\n",
    "    validation_data=(\n",
    "        {\n",
    "            'in_front': x_front_vl,\n",
    "            'in_back': x_back_vl\n",
    "        },\n",
    "        y_vl\n",
    "    ),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ],\n",
    "    \n",
    "    verbose=1\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
