{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hawaiian-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "certified-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSA_Pokemon_df = pd.read_csv('PWCC_Pokemon.csv')\n",
    "PSA_Pokemon_df_9 = PSA_Pokemon_df[(PSA_Pokemon_df.Rating == 9)]\n",
    "PSA_Pokemon_df_10 = PSA_Pokemon_df[(PSA_Pokemon_df.Rating == 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "similar-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names from csv\n",
    "uuid_9 = [[y.split('[')[1].split(']')[0].split(', ')[x][1:-1] for x in range(len(y.split('[')[1].split(']')[0].split(', ')))] for y in list(PSA_Pokemon_df_9.uuid)]\n",
    "uuid_10 = [[y.split('[')[1].split(']')[0].split(', ')[x][1:-1] for x in range(len(y.split('[')[1].split(']')[0].split(', ')))] for y in list(PSA_Pokemon_df_10.uuid)]\n",
    "\n",
    "\n",
    "# File names from directory\n",
    "available_nines = [f.split('.jpg')[0] for f in listdir('PWCC/9') if isfile(join('PWCC/9', f))]\n",
    "available_tens = [f.split('.jpg')[0] for f in listdir('PWCC/10') if isfile(join('PWCC/10', f))]\n",
    "\n",
    "\n",
    "# Only use samples where both photos(front and back) exist in directory\n",
    "nines_front = []\n",
    "nines_back = []\n",
    "for i in uuid_9:\n",
    "    if (i[0] in available_nines) and (i[0] in available_nines):\n",
    "        nines_front.append('PWCC/9/'+str(i[0])+'.jpg')\n",
    "        nines_back.append('PWCC/9/'+str(i[1])+'.jpg')\n",
    "        \n",
    "tens_front = []\n",
    "tens_back = []\n",
    "for i in uuid_10:\n",
    "    if (i[0] in available_tens) and (i[0] in available_tens):\n",
    "        tens_front.append('PWCC/10/'+str(i[0])+'.jpg')\n",
    "        tens_back.append('PWCC/10/'+str(i[1])+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bearing-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13654\n",
       "1    13654\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = min(len(nines_front), len(tens_front))\n",
    "\n",
    "image_front = nines_front[:sample_size] + tens_front[:sample_size]\n",
    "image_back = nines_back[:sample_size] + tens_back[:sample_size]\n",
    "\n",
    "y = [1 for i in tens_front[:sample_size]] + [0 for i in nines_front[:sample_size]]\n",
    "y = pd.DataFrame(y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "indirect-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea43b21b586461592e45224b30aa3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27308 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "res = 224\n",
    "\n",
    "# Load front and back from paths and concat horizontally\n",
    "def load_image(fr,ba):\n",
    "    image_fr = Image.open(fr).convert('LA').resize((res, res))\n",
    "    image_ba = Image.open(ba).convert('LA').resize((res, res))\n",
    "    img = np.concatenate((image_fr, image_ba), axis = 1)\n",
    "    arr = np.array(img)\n",
    "    return arr\n",
    "\n",
    "images = np.array([load_image(image_front[i],image_back[i]) for i in tqdm(range(len(image_front)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "compliant-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr, x_vl, y_tr, y_vl = train_test_split(\n",
    "    images,\n",
    "    y,\n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "comic-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, GRU, LSTM, Bidirectional, TimeDistributed, Attention, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "in_front = keras.Input(batch_shape=(None, (res), (res*2), 2))\n",
    "\n",
    "#Front\n",
    "cov_0 = Conv2D(32, (5, 5), activation='relu')(in_front)\n",
    "pool_0 = MaxPool2D((2, 2))(cov_0)\n",
    "cov_1 = Conv2D(64, (5, 5), activation='relu')(pool_0)\n",
    "pool_1 = MaxPool2D((2, 2))(cov_1)\n",
    "cov_2 = Conv2D(64, (5, 5), activation='relu')(pool_1)\n",
    "pool_2 = MaxPool2D((2, 2))(cov_2)\n",
    "cov_3 = Conv2D(64, (5, 5), activation='relu')(pool_2)\n",
    "pool_3 = MaxPool2D((2, 2))(cov_3)\n",
    "\n",
    "# I usually don't use this layer\n",
    "cov_4 = Conv2D(128, (5, 5), activation='relu')(pool_3)\n",
    "pool_4 = MaxPool2D((6, 6))(cov_4)\n",
    "\n",
    "\n",
    "flatten = Flatten()(pool_4)\n",
    "\n",
    "\n",
    "fc = Dense(64, activation='relu')(flatten)\n",
    "pred = Dense(1, activation='sigmoid')(fc)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs={\n",
    "        'in_front': in_front\n",
    "    },\n",
    "    outputs=pred,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "scenic-prairie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 224, 448, 2)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 220, 444, 32)      1632      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 110, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 106, 218, 64)      51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 53, 109, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 49, 105, 64)       102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 24, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 20, 48, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 10, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 6, 20, 128)        204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 1, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                24640     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 487,457\n",
      "Trainable params: 487,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(lr=0.0003),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'AUC']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "driving-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "683/683 [==============================] - 1767s 3s/step - loss: 1.0000 - accuracy: 0.5738 - auc: 0.5978 - val_loss: 0.6437 - val_accuracy: 0.6130 - val_auc: 0.7112\n",
      "Epoch 2/100\n",
      "683/683 [==============================] - 1715s 3s/step - loss: 0.6206 - accuracy: 0.6448 - auc: 0.7061 - val_loss: 0.6258 - val_accuracy: 0.6243 - val_auc: 0.7367\n",
      "Epoch 3/100\n",
      "683/683 [==============================] - 1718s 3s/step - loss: 0.6008 - accuracy: 0.6635 - auc: 0.7317 - val_loss: 0.5954 - val_accuracy: 0.6692 - val_auc: 0.7349\n",
      "Epoch 4/100\n",
      "683/683 [==============================] - 1726s 3s/step - loss: 0.5914 - accuracy: 0.6708 - auc: 0.7435 - val_loss: 0.6139 - val_accuracy: 0.6679 - val_auc: 0.7481\n",
      "Epoch 5/100\n",
      "683/683 [==============================] - 1702s 2s/step - loss: 0.5780 - accuracy: 0.6873 - auc: 0.7606 - val_loss: 0.5866 - val_accuracy: 0.6748 - val_auc: 0.7596\n",
      "Epoch 6/100\n",
      "683/683 [==============================] - 1704s 2s/step - loss: 0.5705 - accuracy: 0.6934 - auc: 0.7667 - val_loss: 0.5844 - val_accuracy: 0.6849 - val_auc: 0.7652\n",
      "Epoch 7/100\n",
      "683/683 [==============================] - 1700s 2s/step - loss: 0.5632 - accuracy: 0.7061 - auc: 0.7772 - val_loss: 0.6075 - val_accuracy: 0.6629 - val_auc: 0.7622\n",
      "Epoch 8/100\n",
      "683/683 [==============================] - 1698s 2s/step - loss: 0.5500 - accuracy: 0.7113 - auc: 0.7902 - val_loss: 0.5980 - val_accuracy: 0.6840 - val_auc: 0.7570\n",
      "Epoch 9/100\n",
      "683/683 [==============================] - 1699s 2s/step - loss: 0.5299 - accuracy: 0.7357 - auc: 0.8102 - val_loss: 0.5714 - val_accuracy: 0.6972 - val_auc: 0.7717\n",
      "Epoch 10/100\n",
      "683/683 [==============================] - 1695s 2s/step - loss: 0.5169 - accuracy: 0.7404 - auc: 0.8207 - val_loss: 0.5756 - val_accuracy: 0.6943 - val_auc: 0.7748\n",
      "Epoch 11/100\n",
      "683/683 [==============================] - 1698s 2s/step - loss: 0.4923 - accuracy: 0.7574 - auc: 0.8400 - val_loss: 0.6015 - val_accuracy: 0.6871 - val_auc: 0.7675\n",
      "Epoch 12/100\n",
      "683/683 [==============================] - 1692s 2s/step - loss: 0.4703 - accuracy: 0.7714 - auc: 0.8558 - val_loss: 0.5770 - val_accuracy: 0.7025 - val_auc: 0.7753\n",
      "Epoch 13/100\n",
      "683/683 [==============================] - 1699s 2s/step - loss: 0.4429 - accuracy: 0.7898 - auc: 0.8743 - val_loss: 0.5832 - val_accuracy: 0.7005 - val_auc: 0.7700\n",
      "Epoch 14/100\n",
      "683/683 [==============================] - 1691s 2s/step - loss: 0.4269 - accuracy: 0.8005 - auc: 0.8840 - val_loss: 0.6183 - val_accuracy: 0.6963 - val_auc: 0.7698\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x={\n",
    "        'in_front': x_tr\n",
    "    },\n",
    "    y=y_tr,\n",
    "    \n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "\n",
    "    validation_data=(\n",
    "        {\n",
    "            'in_front': x_vl\n",
    "        },\n",
    "        y_vl\n",
    "    ),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    ],\n",
    "    \n",
    "    verbose=1\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "thorough-jungle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2234,  540],\n",
       "       [1114, 1574]])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sig(x):\n",
    "    if x>0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "vl_prediction = model.predict({'in_front': x_vl})\n",
    "vl_prediction = [sig(x) for x in [x[0] for x in list(vl_prediction)]]\n",
    "conf_matrix = tf.math.confusion_matrix(list(y_vl[0]),vl_prediction)\n",
    "conf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
